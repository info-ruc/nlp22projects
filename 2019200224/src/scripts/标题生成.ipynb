{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4246\n",
      "4246\n"
     ]
    }
   ],
   "source": [
    "data_file_path=r'C:\\Users\\hp\\Desktop\\NLP-master\\cnews.train\\cnews.train.txt'\n",
    "with open(data_file_path,'r',encoding='utf-8') as f:\n",
    "    lines=f.readlines()\n",
    "\n",
    "titles=[]\n",
    "texts=[]\n",
    "for news in lines[:10000]:\n",
    "    news=news[3:]\n",
    "    if('新浪体育讯' in news):\n",
    "        title=news.split('新浪体育讯')[0]\n",
    "        text=''.join(news.split('新浪体育讯')[1:])\n",
    "        titles.append(title.strip())\n",
    "        texts.append(text.strip())\n",
    "print(len(titles))\n",
    "print(len(texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "布泽尔首战公牛惨负魔术 德克10分小牛大胜森林狼\n",
      "北京时间12月2日，黄蜂主场力取山猫；公牛回到了久违的主场，而且迎来了卡洛斯-布泽尔，但遭到魔术的痛击；小牛首发表现平平，但仍主场轻取森林狼。以下是这三场比赛的综述：山猫73-黄蜂89黄蜂(13-5)大将克里斯-保罗只得9分，但助攻14次，大卫-韦斯特22分6个篮板，埃梅卡-奥卡福14分13个篮板。山猫(6-12)二连败。杰拉德-华莱士18分，DJ-奥古斯丁和鲍里斯-迪奥各13分。斯蒂芬-杰克逊被禁赛一场。最后3分06秒山猫又未能得分，比赛的最后9分钟他们只投中一球，仅得4分，糟糕的进攻让他们让胜利拱手相让。最后一节山猫只得11分。魔术107-公牛78魔术(14-4)五连胜。贾米尔-尼尔森拿下24分9次助攻，文斯-卡特22分，德怀特-霍华德13分12个篮板，拉沙德-刘易斯13分。替补出场的布兰顿-巴斯得了17分。公牛(9-7)回到主场，卡洛斯-布泽尔首次代表他们亮相，他首发出场，在22分钟内只得5分2个篮板。乔金-诺阿得了16分，但这个联盟第二号篮板手竟然未能抢到一个篮板，德里克-罗斯15分。夏天公牛的唯一收获就是布泽尔，但他由意外受伤，此前一直缺阵，今天才首次亮相。布泽尔表现得正像一个很久未打球的球员，未能给公牛带来太大的帮助。他们刚结束漫长的客场旅行，虽然回到主场，仍是显得疲惫。首节公牛只以22-28落后，但魔术以一波16-4开始第二节，一举以44-26拉开差距。公牛在本节打了7分钟后只投中两球，本节他们只得15分，而魔术得了33分。半场结束时，公牛以37-61落后。下半场魔术一直保持两位数的优势，最多时领先了26分。森林狼86-小牛100（点击观看视频集锦）小牛(14-4)七连胜。首发只有德克-诺维茨基和卡隆-巴特勒刚好得了10分，其他人得分都未能上双，泰森-钱德勒抢下了18个篮板。替补出场的肖恩-马里昂16分最高，杰森-特里12分，胡安-巴里亚14分。森林狼(4-14)五连败。迈克尔-比斯利16分，凯文-勒夫12分15个篮板，达科-米利西奇12分8个篮板。小牛首发五虎状态一般，诺维茨基也一反此前连砍高分的常态，开场后命中率不高。尽管如此，小牛还是早早控制局面，在第二节还有2人22秒时以53-37领先。半场结束时，森林狼只能将比分追成43-55。下半场小牛继续扩大优势，第三节结束前卡迪纳尔三分命中，他们以83-64领先了19分。大比分领先的小牛第四节给了替补更多机会，他们很快取得20分以上的优势，早早锁定胜局。(吴哥)\n"
     ]
    }
   ],
   "source": [
    "print(titles[800])\n",
    "print(texts[800])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "title_len_avg:23.757654\n",
      "title_len_middle:23.000000\n",
      "title_len_min:13.000000\n",
      "title_len_max:30.000000\n",
      "text_len_avg:838.758832\n",
      "text_len_middle:813.000000\n",
      "text_len_min:48.000000\n",
      "text_len_max:12395.000000\n"
     ]
    }
   ],
   "source": [
    "titles_lens=[]\n",
    "texts_lens=[]\n",
    "for line in titles:\n",
    "    titles_lens.append(len(line))\n",
    "for line in texts:\n",
    "    texts_lens.append(len(line))\n",
    "titles_lens.sort()\n",
    "print('title_len_avg:%f'%(sum(titles_lens)/len(titles)))\n",
    "print('title_len_middle:%f'%(titles_lens[int(len(titles)/2)]))\n",
    "print('title_len_min:%f'%(titles_lens[0]))\n",
    "print('title_len_max:%f'%(titles_lens[len(titles)-1]))\n",
    "texts_lens.sort()\n",
    "print('text_len_avg:%f'%(sum(texts_lens)/len(texts)))\n",
    "print('text_len_middle:%f'%(texts_lens[int(len(texts)/2)]))\n",
    "print('text_len_min:%f'%(texts_lens[0]))\n",
    "print('text_len_max:%f'%(texts_lens[len(texts)-1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import jieba\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, LSTM, Dense,Embedding\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache C:\\Users\\Public\\Documents\\Wondershare\\CreatorTemp\\jieba.cache\n",
      "Loading model cost 0.537 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46706\n",
      "46702\n"
     ]
    }
   ],
   "source": [
    "MAX_WORDS=10000\n",
    "\n",
    "#将句子分词并用空格隔开\n",
    "inputTextList=[' '.join([w for w in jieba.cut(text)]) for text in texts]\n",
    "targetTextList=[' '.join([w for w in jieba.cut(text)]) for text in titles]\n",
    "\n",
    "#-4的原因是后面会加上4个特殊字符串，值从1开始，故词典里只设置9999个词\n",
    "tokenizer=Tokenizer(num_words=MAX_WORDS-5)\n",
    "tokenizer.fit_on_texts(texts=inputTextList+targetTextList)\n",
    "\n",
    "word_index=tokenizer.word_index\n",
    "\n",
    "# 增加特殊编码\n",
    "SPECIAL_CODES = ['<PAD>', '<EOS>', '<UNK>', '<GO>']\n",
    "\n",
    "for i,w in enumerate(SPECIAL_CODES):\n",
    "    word_index[w]=MAX_WORDS-i-1\n",
    "\n",
    "re_word_index = dict([(i, t) for t, i in word_index.items()])\n",
    "\n",
    "with open('AutoDigestGeneration_Dict.txt','w',encoding='utf-8') as f:\n",
    "    f.write(str(word_index))\n",
    "\n",
    "#将文本映射为数字序列\n",
    "input_sequences=tokenizer.texts_to_sequences(texts=inputTextList)\n",
    "target_sequences=tokenizer.texts_to_sequences(texts=targetTextList)\n",
    "\n",
    "print(len(word_index))\n",
    "print(len(re_word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[82, 28, 79, 37, 40, 49, 1, 297, 103, 2621, 366, 206, 197, 397, 5, 4068, 2, 103, 1, 266, 769, 5, 1328, 1115, 1, 27, 998, 175, 2, 6028, 206, 213, 176, 65, 2659, 1, 27, 419, 103, 2154, 385, 3, 620, 7, 23, 781, 9, 2, 1708, 16, 366, 1864, 297, 985, 297, 141, 56, 1421, 439, 291, 867, 87, 8, 1, 27, 59, 156, 36, 1, 883, 803, 273, 8, 63, 30, 26, 1, 3433, 1898, 156, 8, 141, 30, 26, 3, 366, 63, 79, 614, 212, 3, 1925, 881, 207, 8, 1, 3598, 2593, 11, 4155, 2709, 1501, 141, 8, 3, 1844, 480, 48, 2283, 146, 3, 86, 39, 8, 1900, 75, 366, 94, 517, 85, 1, 9, 2, 86, 87, 125, 17, 166, 307, 251, 172, 1, 6217, 53, 8, 1, 760, 2, 66, 41, 17, 41, 229, 3, 86, 623, 366, 867, 81, 8, 3, 175, 1601, 197, 1672, 175, 156, 53, 938, 214, 3, 608, 812, 1151, 122, 268, 8, 87, 36, 59, 1, 2603, 937, 273, 8, 1, 1064, 260, 141, 8, 79, 30, 26, 1, 1447, 376, 141, 8, 3, 173, 170, 2, 217, 1406, 2108, 91, 5, 201, 8, 3, 197, 87, 68, 397, 103, 1, 1328, 1115, 585, 1036, 17, 2069, 1, 6, 176, 170, 1, 4, 273, 125, 429, 867, 56, 8, 40, 30, 26, 3, 2324, 5, 179, 8, 1, 27, 116, 99, 26, 1507, 944, 517, 549, 50, 42, 26, 1, 661, 357, 159, 8, 3, 772, 197, 2, 678, 1773, 97, 1115, 1, 27, 6, 662, 1305, 325, 1, 329, 191, 461, 1, 73, 231, 585, 2069, 3, 1115, 65, 91, 42, 1221, 400, 2, 29, 1, 517, 118, 197, 593, 2964, 2, 250, 3, 17, 1136, 137, 3117, 2, 124, 4233, 1, 145, 397, 103, 1, 419, 7, 930, 4150, 3, 350, 197, 1577, 273, 410, 269, 1, 27, 175, 2073, 179, 53, 112, 326, 1, 1043, 60, 987, 337, 804, 428, 3, 197, 4, 691, 76, 5, 68, 125, 54, 166, 307, 2460, 1, 346, 423, 17, 867, 159, 8, 1, 32, 175, 91, 5, 580, 8, 3, 464, 137, 64, 1, 197, 60, 698, 1975, 269, 3, 463, 175, 191, 408, 1014, 2, 196, 1, 8676, 120, 5, 337, 8, 3, 385, 1744, 213, 758, 1793, 1185, 1098, 673, 1235, 1774, 213, 156, 53, 2010, 214, 3, 176, 155, 1118, 738, 11, 3100, 1304, 5052, 91, 5, 78, 8, 1, 1674, 85, 20, 517, 35, 624, 1, 2994, 860, 458, 5, 207, 30, 26, 3, 173, 170, 2, 793, 2311, 179, 8, 441, 1, 814, 1032, 79, 8, 1, 3512, 2269, 2004, 156, 8, 3, 385, 53, 156, 938, 212, 3, 882, 1241, 1313, 179, 8, 1, 391, 634, 79, 8, 159, 30, 26, 1, 4122, 3909, 1368, 79, 8, 71, 30, 26, 3, 213, 176, 2778, 192, 816, 1, 738, 10, 329, 550, 322, 3485, 2, 1, 740, 54, 182, 3947, 3, 3035, 1, 213, 121, 1830, 829, 978, 1, 4, 326, 135, 40, 58, 273, 75, 64, 60, 1297, 698, 120, 3, 464, 137, 64, 1, 385, 396, 33, 210, 713, 923, 1248, 3, 463, 213, 272, 748, 196, 1, 263, 137, 74, 70, 1, 17, 60, 1277, 1728, 120, 5, 241, 8, 3, 2097, 120, 2, 213, 222, 118, 5, 173, 96, 113, 126, 1, 17, 733, 270, 160, 8, 1046, 2, 196, 1, 1830, 1171, 1484, 3, 898]\n",
      "北京时间12月2日，黄蜂主场力取山猫；公牛回到了久违的主场，而且迎来了卡洛斯布泽尔，但遭到魔术的痛击；小牛首发表现平平，但仍主场轻取森林狼。以下是这三场比赛的综述：山猫73黄蜂89黄蜂135大将克里斯保罗只得9分，但助攻14次，大卫韦斯特22分6个篮板，埃梅卡奥卡福14分13个篮板。山猫612二连败。杰拉德华莱士18分，dj奥古斯丁和鲍里斯迪奥各13分。斯蒂芬杰克逊被禁赛一场。最后3分06秒山猫又未能得分，比赛的最后9分钟他们只投中一球，仅得4分，糟糕的进攻让他们让胜利。最后一节山猫只得11分。魔术107公牛78魔术144五连胜。贾米尔尼尔森拿下24分9次助攻，文斯卡特22分，德怀特霍华德13分12个篮板，拉沙德刘易斯13分。替补出场的布兰顿巴斯得了17分。公牛97回到主场，卡洛斯布泽尔首次代表他们亮相，他首发出场，在22分钟内只得5分2个篮板。乔金了16分，但这个联盟篮板手竟然未能抢到一个篮板，德里克罗斯15分。夏天公牛的唯一收获就是布泽尔，但他由意外受伤，此前一直缺阵，今天才首次亮相。布泽尔表现得一个未打球的球员，未能给公牛带来太大的帮助。他们刚结束漫长的客场旅行，虽然回到主场，仍是显得疲惫。首节公牛只以2228落后，但魔术以一波164开始第二节，一举以4426拉开差距。公牛在本节打了7分钟后只投中两球，本节他们只得15分，而魔术得了33分。半场结束时，公牛以3761落后。下半场魔术一直保持两位数的优势，最多时领先了26分。森林狼86小牛100（点击观看视频集锦）小牛144七连胜。首发只有德克诺维茨基和卡隆巴特勒刚好得了10分，其他人得分都未能上双，泰森钱德勒抢下了18个篮板。替补出场的肖恩马里昂16分最高，杰森特里12分，胡安巴里亚14分。森林狼414五连败。迈克尔比斯利16分，凯文勒夫12分15个篮板，达科米利西奇12分8个篮板。小牛首发五虎状态一般，诺维茨基也此前连砍高分的，开场后命中率不高。尽管如此，小牛还是早早控制局面，在第二节还有2人22秒时以5337领先。半场结束时，森林狼只能将比分追成4355。下半场小牛继续扩大优势，第三节结束三分命中，他们以8364领先了19分。大比分领先的小牛第四节给了替补更多机会，他们很快取得20分以上的优势，早早锁定胜局。吴哥"
     ]
    }
   ],
   "source": [
    "print(input_sequences[800])\n",
    "\n",
    "for n in input_sequences[800]:\n",
    "    print(re_word_index[n],end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "title_len_avg:478.819830\n",
      "title_len_middle:465.000000\n",
      "title_len_min:26.000000\n",
      "title_len_max:6457.000000\n",
      "text_len_avg:10.961611\n",
      "text_len_middle:11.000000\n",
      "text_len_min:3.000000\n",
      "text_len_max:19.000000\n"
     ]
    }
   ],
   "source": [
    "titles_lens=[]\n",
    "texts_lens=[]\n",
    "for line in input_sequences:\n",
    "    titles_lens.append(len(line))\n",
    "for line in target_sequences:\n",
    "    texts_lens.append(len(line))\n",
    "titles_lens.sort()\n",
    "print('title_len_avg:%f'%(sum(titles_lens)/len(titles)))\n",
    "print('title_len_middle:%f'%(titles_lens[int(len(titles)/2)]))\n",
    "print('title_len_min:%f'%(titles_lens[0]))\n",
    "print('title_len_max:%f'%(titles_lens[len(titles)-1]))\n",
    "texts_lens.sort()\n",
    "print('text_len_avg:%f'%(sum(texts_lens)/len(texts)))\n",
    "print('text_len_middle:%f'%(texts_lens[int(len(texts)/2)]))\n",
    "print('text_len_min:%f'%(texts_lens[0]))\n",
    "print('text_len_max:%f'%(texts_lens[len(texts)-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#因此确定\n",
    "Tx=500\n",
    "Ty=20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 4246/4246 [00:00<00:00, 116625.94it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 4246/4246 [00:00<00:00, 607360.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4246, 500)\n",
      "(4246, 20)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#padding数据\n",
    "import tqdm\n",
    "\n",
    "input_arr=[]\n",
    "target_arr=[]\n",
    "\n",
    "for line in tqdm.tqdm(input_sequences):\n",
    "    slen=len(line)\n",
    "    if(slen<Tx):\n",
    "        newline=line+[word_index['<PAD>']]*(Tx-slen)\n",
    "        input_arr.append(newline)\n",
    "    else:\n",
    "        input_arr.append(line[:Tx])\n",
    "\n",
    "\n",
    "for line in tqdm.tqdm(target_sequences):\n",
    "    slen=len(line)\n",
    "    if(slen<Ty):\n",
    "        line.append(word_index['<EOS>'])\n",
    "        newline=line+[word_index['<PAD>']]*(Ty-slen-1)\n",
    "        target_arr.append(newline)\n",
    "    else:\n",
    "        target_arr.append(line[:Ty])\n",
    "\n",
    "input_arr=np.array(input_arr)\n",
    "target_arr=np.array(target_arr)\n",
    "\n",
    "print(input_arr.shape)\n",
    "print(target_arr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 372 2461  735 1206   38 2543  398 1555    1   27    6  851  290    2\n",
      " 2085   51 4918    5    3  317  387  443    2  133    1  735  106   51\n",
      "  670    5   11  371    2 4305    1  496   33    4 3937  516  397 1106\n",
      "    3 4318    1  710   94   67  348 1198  642 4479 7282  816    2 3703\n",
      "  104    6    4  588 3166 7362    5    3  735   11 8338  135    6    2\n",
      " 9756   20    7  132   93  107    2 1797    1 8338  251   20   61  178\n",
      "  118  735   11    6    2   19 8777    1 1137   10  733  165    5  735\n",
      "    2 3695    3  501    1 1137   10    7  128   14  505  680    2 3085\n",
      " 2372  921    1  441    2    3 8338 7741  538   64   24  519   43  556\n",
      "    2  857 1089    1 1137  141  531  112    1 1825  102  652 7253  374\n",
      "  578 1965  383   21  374  383  426 6680    3  145 4119   60 5548    2\n",
      "   12   13 3851  302    1   27 1137    2 3693 2672    7   14  152    2\n",
      " 9425    3  167 1721 1349    5  374  383 7765 4254    2    1    7  609\n",
      "   12  152 4479    2   13  535    3   18  154  335  164 1137 7438    7\n",
      "    2    1 1137 8033  102   53   37  410 7468    2    1  519   56    3\n",
      " 4340  519 5390   21 4193   21   11   58    2    1 7742    7   11  609\n",
      "    2    3   23   24 1418    5 8338    2   11 1761    2 3891    3    2\n",
      " 3703 4658   97   42    1 2043 2992 3828 2017    2    3  609    2 8338\n",
      " 7741   97  105    2    1 1137 1453 3703    2 2156  281 2043    3 1137\n",
      " 5708 3471    1 1716  808 8680 2043    2   16   21 6455   21 4039   21\n",
      " 1624   11   55 1137  211   20    7 2043   14 2109 2005    2  404    3\n",
      "  893  191  799 1305    2    7 2364    4 7908  116    1 8338  369   67\n",
      " 1331   52    2    3 1137  378  167 1721   48 6868   12 4727  152 4479\n",
      "    2 3703   13  109 6265    1  574 1137 2306 8344  136 1714    3 1137\n",
      "  335  164  374  383    1  432    7  374  383    4   34 1137 3061    2\n",
      "  204   89   12   13    5 1137    2 3799    5 6094    3  145  191    4\n",
      " 9832  177 1005    5    2 8254    1   27  279 2320   35 3771    2 5757\n",
      " 2641  136   41 8338 7741 1093    5 4486    3    4  609 2320  374  383\n",
      " 3771    2 8854 2641   14    1 8338 7741    2 2641    1   23   41  710\n",
      "  384  703    5 1387 1137    4  710 2116 1005    2 1675    3 1808   11\n",
      " 3960   35    2  117    1 8338  476   55  443   46   16   12   95  163\n",
      "  227  664    1   15 1714  234    4 3908  810   31 1100 8390  234 4897\n",
      "  374  383 2455  118  246   58    1 1983 2118   61   18   15    2    3\n",
      "   13  406  106    1 1137    2 2641  136 4030    2   48 3601    4    5\n",
      " 2320   35    3  255   31  183  735  331    5  364 2641   88   61 8678\n",
      " 7216    3 3238 2178 9999 9999 9999 9999 9999 9999]\n",
      "[ 128  152  154 1507 1101 9386 1734 9998 9999 9999 9999 9999 9999 9999\n",
      " 9999 9999 9999 9999 9999 9999]\n"
     ]
    }
   ],
   "source": [
    "print(input_arr[800])\n",
    "print(target_arr[800])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "# 自定义softmax函数\n",
    "def softmax(x, axis=1):\n",
    "    ndim = K.ndim(x)\n",
    "    if ndim == 2:\n",
    "        return K.softmax(x)\n",
    "    elif ndim > 2:\n",
    "        e = K.exp(x - K.max(x, axis=axis, keepdims=True))\n",
    "        s = K.sum(e, axis=axis, keepdims=True)\n",
    "        return e / s\n",
    "    else:\n",
    "        raise ValueError('Cannot apply softmax to a tensor that is 1D')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import *\n",
    "\n",
    "# 定义全局网络层对象\n",
    "repeator = RepeatVector(Tx)\n",
    "concatenator = Concatenate(axis=-1)\n",
    "densor_tanh = Dense(32, activation = \"tanh\")\n",
    "densor_relu = Dense(1, activation = \"relu\")\n",
    "densor_con = Dense(256, activation = \"relu\")\n",
    "activator = Activation(softmax, name='attention_weights')\n",
    "dotor = Dot(axes = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_step_attention(a, s_prev):\n",
    "    # 将s_prev复制Tx次\n",
    "    s_prev = repeator(s_prev)\n",
    "    # 拼接BiRNN隐层状态与s_prev\n",
    "    concat = concatenator([a, s_prev])\n",
    "    # 计算energies\n",
    "    e = densor_tanh(concat)\n",
    "    energies = densor_relu(e)\n",
    "    # 计算weights\n",
    "    alphas = activator(energies)\n",
    "    # 加权得到Context Vector\n",
    "    context = dotor([alphas, a])\n",
    "    \n",
    "    return context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载预训练好的glove词向量\n",
    "with open(r'C:\\Users\\hp\\Desktop\\NLP-master\\sgns.zhihu.word\\sgns.zhihu.word', 'r',encoding='utf-8') as f:\n",
    "    words = set()\n",
    "    word_to_vec_map = {}\n",
    "    for line in f:\n",
    "        line = line.strip().split()\n",
    "        curr_word = line[0]\n",
    "        words.add(curr_word)\n",
    "        word_to_vec_map[curr_word] = np.array(line[1:], dtype=np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretrained_embedding_layer(word_to_vec_map, word_index):\n",
    "    vocab_len = len(word_index) + 1        # Keras Embedding的API要求+1\n",
    "    emb_dim = 300\n",
    "    # 初始化embedding矩阵\n",
    "    emb_matrix = np.zeros((vocab_len, emb_dim))\n",
    "    # 用词向量填充embedding矩阵\n",
    "    for word, index in word_index.items():\n",
    "        word_vector = word_to_vec_map.get(word, np.zeros(emb_dim))\n",
    "        emb_matrix[index, :] = word_vector\n",
    "    # 定义Embedding层，并指定不需要训练该层的权重\n",
    "    embedding_layer = Embedding(vocab_len, emb_dim, trainable=False)\n",
    "    # build\n",
    "    embedding_layer.build((None,))\n",
    "    # set weights\n",
    "    embedding_layer.set_weights([emb_matrix])\n",
    "    return embedding_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取Embedding layer\n",
    "embedding_layer = pretrained_embedding_layer(word_to_vec_map, word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "def train_gen(X,Y,Ty,n_s,batch_size=64):\n",
    "    xlen=X.shape[0]\n",
    "    permutation = np.random.permutation(xlen)\n",
    "    x = X[permutation]\n",
    "    y = Y[permutation]\n",
    "    num_batches = int(xlen/batch_size)\n",
    "    \n",
    "    while 1:\n",
    "        for i in range(num_batches):\n",
    "            x_batch=x[i*batch_size:(i+1)*batch_size]\n",
    "            y_batch=y[i*batch_size:(i+1)*batch_size]\n",
    "            s0=np.zeros((batch_size,n_s))\n",
    "            c0=np.zeros((batch_size,n_s))\n",
    "            out0=np.zeros((batch_size,MAX_WORDS))#加一的原因是字典中的值从1开始\n",
    "            outputs=np.zeros((batch_size,Ty,MAX_WORDS))\n",
    "            for i,line in enumerate(y_batch):\n",
    "                for j,index in enumerate(line):\n",
    "                    outputs[i,j,index]=1\n",
    "                    \n",
    "            #outputs=np.array(list(map(lambda x: to_categorical(x, num_classes=MAX_WORDS), y_batch)))\n",
    "            outputs = list(outputs.swapaxes(0,1))\n",
    "            yield [x_batch,s0,c0,out0],outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_a = 128 # The hidden size of Bi-LSTM\n",
    "n_s = 128 # The hidden size of LSTM in Decoder\n",
    "decoder_LSTM_cell = LSTM(n_s, return_state=True)\n",
    "output_layer = Dense(MAX_WORDS, activation=softmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义网络层对象（用在model函数中）\n",
    "reshapor = Reshape((1, MAX_WORDS))\n",
    "concator = Concatenate(axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(Tx, Ty, n_encoder, n_decoder):\n",
    "    \"\"\"\n",
    "    构造模型\n",
    "    @param Tx: 输入序列的长度\n",
    "    @param Ty: 输出序列的长度\n",
    "    @param n_encoder: Encoder端Bi-LSTM隐层结点数\n",
    "    @param n_decoder: Decoder端LSTM隐层结点数\n",
    "    \"\"\"\n",
    "    \n",
    "    # 定义输入层\n",
    "    X = Input(shape=(Tx,))\n",
    "    # Embedding层\n",
    "    embed = embedding_layer(X)\n",
    "    \n",
    "    # 定义Bi-LSTM\n",
    "    a = Bidirectional(LSTM(n_decoder, return_sequences=True))(embed)\n",
    "    \n",
    "    # Decoder端LSTM的初始状态\n",
    "    s0 = Input(shape=(n_decoder,), name='s0')\n",
    "    c0 = Input(shape=(n_decoder,), name='c0')\n",
    "    \n",
    "    # Decoder端LSTM的初始输入\n",
    "    out0 = Input(shape=(MAX_WORDS, ), name='out0')\n",
    "    out = reshapor(out0)\n",
    "    \n",
    "    s = s0\n",
    "    c = c0\n",
    "    \n",
    "    # 模型输出列表，用来存储翻译的结果\n",
    "    outputs = []\n",
    "    \n",
    "    # Decoder端，迭代Ty轮，每轮生成一个翻译结果\n",
    "    for t in range(Ty):\n",
    "        # 获取Context Vector\n",
    "        context = one_step_attention(a, s)\n",
    "        \n",
    "        # 将Context Vector与上一轮的翻译结果进行concat\n",
    "        con_out=densor_con(reshapor(out))\n",
    "        context = concator([context,con_out])\n",
    "        s, _, c = decoder_LSTM_cell(context, initial_state=[s, c])\n",
    "        \n",
    "        # 将LSTM的输出结果与全连接层链接\n",
    "        out = output_layer(s)\n",
    "        \n",
    "        # 存储输出结果\n",
    "        outputs.append(out)\n",
    "    \n",
    "    model = Model([X, s0, c0, out0], outputs)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model(Tx, Ty, n_a, n_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model/model_to_dot to work.\n"
     ]
    }
   ],
   "source": [
    "from keras.utils.vis_utils import plot_model\n",
    "plot_model(model,to_file='attentionTest_model.png',show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import adam_v2\n",
    "from keras.models import load_model\n",
    "import keras.backend as K\n",
    "'''\n",
    "out = model.compile(optimizer=Adam(lr=0.1, beta_1=0.9, beta_2=0.999, decay=0.001),\n",
    "                    metrics=['accuracy'],\n",
    "                    loss='categorical_crossentropy')\n",
    "'''\n",
    "out = model.compile(optimizer='rmsprop',\n",
    "                    metrics=['accuracy'],\n",
    "                    loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Public\\Documents\\Wondershare\\CreatorTemp/ipykernel_11556/3907132207.py:4: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  model.fit_generator(train_gen(input_arr,target_arr,Ty,n_s,batch_size=8),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1061/1061 [==============================] - 956s 872ms/step - loss: 88.8389 - dense_3_loss: 6.6072 - dense_3_1_loss: 7.0508 - dense_3_2_loss: 7.3391 - dense_3_3_loss: 7.5372 - dense_3_4_loss: 7.5707 - dense_3_5_loss: 7.5989 - dense_3_6_loss: 7.5369 - dense_3_7_loss: 7.4504 - dense_3_8_loss: 7.1082 - dense_3_9_loss: 6.6295 - dense_3_10_loss: 5.5975 - dense_3_11_loss: 4.2424 - dense_3_12_loss: 2.8150 - dense_3_13_loss: 1.6236 - dense_3_14_loss: 0.8551 - dense_3_15_loss: 0.4569 - dense_3_16_loss: 0.2783 - dense_3_17_loss: 0.2012 - dense_3_18_loss: 0.1742 - dense_3_19_loss: 0.1658 - dense_3_accuracy: 0.0411 - dense_3_1_accuracy: 0.1115 - dense_3_2_accuracy: 0.0375 - dense_3_3_accuracy: 0.0254 - dense_3_4_accuracy: 0.0398 - dense_3_5_accuracy: 0.0221 - dense_3_6_accuracy: 0.0180 - dense_3_7_accuracy: 0.0310 - dense_3_8_accuracy: 0.0607 - dense_3_9_accuracy: 0.1165 - dense_3_10_accuracy: 0.2258 - dense_3_11_accuracy: 0.3901 - dense_3_12_accuracy: 0.5871 - dense_3_13_accuracy: 0.7687 - dense_3_14_accuracy: 0.8971 - dense_3_15_accuracy: 0.9604 - dense_3_16_accuracy: 0.9854 - dense_3_17_accuracy: 0.9946 - dense_3_18_accuracy: 0.9980 - dense_3_19_accuracy: 0.9985\n",
      "Epoch 2/3\n",
      "1061/1061 [==============================] - 1018s 959ms/step - loss: 81.8921 - dense_3_loss: 5.9613 - dense_3_1_loss: 6.4863 - dense_3_2_loss: 6.8589 - dense_3_3_loss: 7.0247 - dense_3_4_loss: 7.1145 - dense_3_5_loss: 7.1588 - dense_3_6_loss: 7.0711 - dense_3_7_loss: 6.9719 - dense_3_8_loss: 6.6585 - dense_3_9_loss: 6.1923 - dense_3_10_loss: 5.2186 - dense_3_11_loss: 3.9411 - dense_3_12_loss: 2.5952 - dense_3_13_loss: 1.4502 - dense_3_14_loss: 0.7009 - dense_3_15_loss: 0.3027 - dense_3_16_loss: 0.1196 - dense_3_17_loss: 0.0419 - dense_3_18_loss: 0.0148 - dense_3_19_loss: 0.0086 - dense_3_accuracy: 0.0891 - dense_3_1_accuracy: 0.1420 - dense_3_2_accuracy: 0.0569 - dense_3_3_accuracy: 0.0382 - dense_3_4_accuracy: 0.0456 - dense_3_5_accuracy: 0.0318 - dense_3_6_accuracy: 0.0312 - dense_3_7_accuracy: 0.0389 - dense_3_8_accuracy: 0.0656 - dense_3_9_accuracy: 0.1169 - dense_3_10_accuracy: 0.2254 - dense_3_11_accuracy: 0.3916 - dense_3_12_accuracy: 0.5874 - dense_3_13_accuracy: 0.7696 - dense_3_14_accuracy: 0.8979 - dense_3_15_accuracy: 0.9614 - dense_3_16_accuracy: 0.9863 - dense_3_17_accuracy: 0.9955 - dense_3_18_accuracy: 0.9991 - dense_3_19_accuracy: 0.9998\n",
      "Epoch 3/3\n",
      "1061/1061 [==============================] - 958s 903ms/step - loss: 79.6336 - dense_3_loss: 5.7175 - dense_3_1_loss: 6.2488 - dense_3_2_loss: 6.6581 - dense_3_3_loss: 6.7944 - dense_3_4_loss: 6.9073 - dense_3_5_loss: 6.9742 - dense_3_6_loss: 6.8836 - dense_3_7_loss: 6.7996 - dense_3_8_loss: 6.5150 - dense_3_9_loss: 6.0554 - dense_3_10_loss: 5.1044 - dense_3_11_loss: 3.8480 - dense_3_12_loss: 2.5435 - dense_3_13_loss: 1.4232 - dense_3_14_loss: 0.6848 - dense_3_15_loss: 0.2957 - dense_3_16_loss: 0.1152 - dense_3_17_loss: 0.0410 - dense_3_18_loss: 0.0150 - dense_3_19_loss: 0.0089 - dense_3_accuracy: 0.1098 - dense_3_1_accuracy: 0.1457 - dense_3_2_accuracy: 0.0663 - dense_3_3_accuracy: 0.0510 - dense_3_4_accuracy: 0.0501 - dense_3_5_accuracy: 0.0357 - dense_3_6_accuracy: 0.0426 - dense_3_7_accuracy: 0.0434 - dense_3_8_accuracy: 0.0677 - dense_3_9_accuracy: 0.1189 - dense_3_10_accuracy: 0.2276 - dense_3_11_accuracy: 0.3874 - dense_3_12_accuracy: 0.5880 - dense_3_13_accuracy: 0.7697 - dense_3_14_accuracy: 0.8975 - dense_3_15_accuracy: 0.9610 - dense_3_16_accuracy: 0.9861 - dense_3_17_accuracy: 0.9954 - dense_3_18_accuracy: 0.9989 - dense_3_19_accuracy: 0.9996\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x199f9e6b460>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 训练模型\n",
    "xlen=len(input_arr)\n",
    "\n",
    "model.fit_generator(train_gen(input_arr,target_arr,Ty,n_s,batch_size=8),\n",
    "                   steps_per_epoch=int(xlen/4),\n",
    "                   epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('AutoDigestGenerationTest.h5')\n",
    "model.save_weights('AutoDigestGenerationTest_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "model=load_model('AutoDigestGenerationTest.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "北京时间12月2日，黄蜂主场力取山猫；公牛回到了久违的主场，而且迎来了卡洛斯布泽尔，但遭到魔术的痛击；小牛首发表现平平，但仍主场轻取森林狼。以下是这三场比赛的综述：山猫73黄蜂89黄蜂135大将克里斯保罗只得9分，但助攻14次，大卫韦斯特22分6个篮板，埃梅卡奥卡福14分13个篮板。山猫612二连败。杰拉德华莱士18分，dj奥古斯丁和鲍里斯迪奥各13分。斯蒂芬杰克逊被禁赛一场。最后3分06秒山猫又未能得分，比赛的最后9分钟他们只投中一球，仅得4分，糟糕的进攻让他们让胜利。最后一节山猫只得11分。魔术107公牛78魔术144五连胜。贾米尔尼尔森拿下24分9次助攻，文斯卡特22分，德怀特霍华德13分12个篮板，拉沙德刘易斯13分。替补出场的布兰顿巴斯得了17分。公牛97回到主场，卡洛斯布泽尔首次代表他们亮相，他首发出场，在22分钟内只得5分2个篮板。乔金了16分，但这个联盟篮板手竟然未能抢到一个篮板，德里克罗斯15分。夏天公牛的唯一收获就是布泽尔，但他由意外受伤，此前一直缺阵，今天才首次亮相。布泽尔表现得一个未打球的球员，未能给公牛带来太大的帮助。他们刚结束漫长的客场旅行，虽然回到主场，仍是显得疲惫。首节公牛只以2228落后，但魔术以一波164开始第二节，一举以4426拉开差距。公牛在本节打了7分钟后只投中两球，本节他们只得15分，而魔术得了33分。半场结束时，公牛以3761落后。下半场魔术一直保持两位数的优势，最多时领先了26分。森林狼86小牛100（点击观看视频集锦）小牛144七连胜。首发只有德克诺维茨基和卡隆巴特勒刚好得了10分，其他人得分都未能上双，泰森钱德勒抢下了18个篮板。替补出场的肖恩马里昂16分最高，杰森特里12分，胡安巴里亚14分。森林狼414五连败。迈克尔比斯利16分，凯文勒夫12分15个篮板，达科米利西奇12分8个篮板。小牛首发五虎状态一般，诺维茨基也此前连砍高分的，开场后命中率不高。尽管如此，小牛还是早早控制局面，在第二节还有2人22秒时以5337领先。半场结束时，森林狼只能将比分追成4355。下半场小牛继续扩大优势，第三节结束三分命中，他们以8364领先了19分。大比分领先的小牛第四节给了替补更多机会，他们很快取得20分以上的优势，早早锁定胜局。吴哥\n",
      "[   82    28    79    37    40    49     1   297   103  2621   366   206\n",
      "   197   397     5  4068     2   103     1   266   769     5  1328  1115\n",
      "     1    27   998   175     2  6028   206   213   176    65  2659     1\n",
      "    27   419   103  2154   385     3   620     7    23   781     9     2\n",
      "  1708    16   366  1864   297   985   297 14069  1421   439   291   867\n",
      "    87     8     1    27    59   156    36     1   883   803   273     8\n",
      "    63    30    26     1  3433  1898   156     8   141    30    26     3\n",
      "   366 23022   614   212     3  1925   881   207     8     1  3598  2593\n",
      "    11  4155  2709  1501   141     8     3  1844   480    48  2283   146\n",
      "     3    86    39     8  1900    75   366    94   517    85     1     9\n",
      "     2    86    87   125    17   166   307   251   172     1  6217    53\n",
      "     8     1   760     2    66    41    17    41   229     3    86   623\n",
      "   366   867    81     8     3   175  1601   197  1672   175  9518   938\n",
      "   214     3   608   812  1151   122   268     8    87    36    59     1\n",
      "  2603   937   273     8     1  1064   260   141     8    79    30    26\n",
      "     1  1447   376   141     8     3   173   170     2 11555    91     5\n",
      "   201     8     3   197  1160   397   103     1  1328  1115   585  1036\n",
      "    17  2069     1     6   176   170     1     4   273   125   429   867\n",
      "    56     8    40    30    26     3  2324     5   179     8     1    27\n",
      "   116    99    26  1507   944   517   549    50    42    26     1  2131\n",
      "   159     8     3   772   197     2   678  1773    97  1115     1    27\n",
      "     6   662  1305   325     1   329   191   461     1    73   231   585\n",
      "  2069     3  1115    65    91    42  1221   400     2    29     1   517\n",
      "   118   197   593  2964     2   250     3    17  1136   137  3117     2\n",
      "   124  4233     1   145   397   103     1   419     7   930  4150     3\n",
      "   350   197  1577   269     1    27   175  2073 21403   112   326     1\n",
      "  1043    60   804   428     3   197     4   691    76     5    68   125\n",
      "    54   166   307  2460     1   346   423    17   867   159     8     1\n",
      "    32   175    91     5   580     8     3   464   137    64     1   197\n",
      "    60   269     3   463   175   191   408  1014     2   196     1  8676\n",
      "   120     5   337     8     3   385  1744   213   758  1793  1185  1098\n",
      "   673  1235  1774   213  9518  2010   214     3   176   155  1118   738\n",
      "    11  3100  1304  5052    91     5    78     8     1  1674    85    20\n",
      "   517    35   624     1  2994   860   458     5   207    30    26     3\n",
      "   173   170     2   793  2311   179     8   441     1   814  1032    79\n",
      "     8     1  3512  2269  2004   156     8     3   385   938   212     3\n",
      "   882  1241  1313   179     8     1   391   634    79     8   159    30\n",
      "    26     1  4122   926  1313  1368    79     8    71    30    26     3\n",
      "   213   176  2778   192   816     1   738    10   329   550   322  3485\n",
      "     2     1   740    54   182  3947     3  3035     1   213   121  1830\n",
      "   829   978     1     4   326   135    40    58   273    75    64    60\n",
      "   120     3   464   137    64     1   385   396]\n",
      "[[9999]\n",
      " [   8]\n",
      " [   8]\n",
      " [   8]\n",
      " [   8]\n",
      " [   8]\n",
      " [   8]\n",
      " [   8]\n",
      " [   8]\n",
      " [   8]\n",
      " [   8]\n",
      " [   8]\n",
      " [   8]\n",
      " [   8]\n",
      " [   8]\n",
      " [   8]\n",
      " [   8]\n",
      " [   8]\n",
      " [   8]\n",
      " [   8]]\n",
      "<PAD> 分 分 分 分 分 分 分 分 分 分 分 分 分 分 分 分 分 分 分\n"
     ]
    }
   ],
   "source": [
    "import jieba\n",
    "\n",
    "with open('AutoDigestGeneration_Dict.txt','r',encoding='utf-8') as f:\n",
    "    word_index_str=f.read()\n",
    "    \n",
    "\n",
    "    \n",
    "word_index=eval(word_index_str)\n",
    "re_word_index = dict([(i, t) for t, i in word_index.items()])\n",
    "Tx=500\n",
    "n_decoder=128\n",
    "\n",
    "def make_prediction(sentence):\n",
    "    # 将句子分词后转化为数字编码\n",
    "    input_seq=[]\n",
    "    for w in jieba.cut(sentence):\n",
    "        if w in word_index:\n",
    "            input_seq.append(word_index[w])\n",
    "            \n",
    "    if(len(input_seq)<=Tx):\n",
    "        input_seq = np.array(input_seq + [word_index['PAD']] * (Tx - len(input_seq)))\n",
    "    else:\n",
    "        input_seq = np.array(input_seq[:Tx])\n",
    "    s0=np.zeros((1,n_decoder))\n",
    "    c0=np.zeros((1,n_decoder))\n",
    "    out0=np.zeros((1,MAX_WORDS))\n",
    "    \n",
    "    print(input_seq)\n",
    "    \n",
    "    # 翻译结果\n",
    "    preds = model.predict([input_seq.reshape(-1,Tx), s0, c0, out0])\n",
    "    predictions = np.argmax(preds, axis=-1)\n",
    "    \n",
    "    print(predictions)\n",
    "    \n",
    "    # 转换为单词\n",
    "    idx = [re_word_index.get(idx[0], \"<UNK>\") for idx in predictions]\n",
    "    \n",
    "    # 返回句子\n",
    "    return \" \".join(idx)\n",
    "\n",
    "\n",
    "text='''\n",
    "北京时间12月2日，黄蜂主场力取山猫；公牛回到了久违的主场，而且迎来了卡洛斯布泽尔，但遭到魔术的痛击；小牛首发表现平平，但仍主场轻取森林狼。以下是这三场比赛的综述：山猫73黄蜂89黄蜂135大将克里斯保罗只得9分，但助攻14次，大卫韦斯特22分6个篮板，埃梅卡奥卡福14分13个篮板。山猫612二连败。杰拉德华莱士18分，dj奥古斯丁和鲍里斯迪奥各13分。斯蒂芬杰克逊被禁赛一场。最后3分06秒山猫又未能得分，比赛的最后9分钟他们只投中一球，仅得4分，糟糕的进攻让他们让胜利。最后一节山猫只得11分。魔术107公牛78魔术144五连胜。贾米尔尼尔森拿下24分9次助攻，文斯卡特22分，德怀特霍华德13分12个篮板，拉沙德刘易斯13分。替补出场的布兰顿巴斯得了17分。公牛97回到主场，卡洛斯布泽尔首次代表他们亮相，他首发出场，在22分钟内只得5分2个篮板。乔金了16分，但这个联盟篮板手竟然未能抢到一个篮板，德里克罗斯15分。夏天公牛的唯一收获就是布泽尔，但他由意外受伤，此前一直缺阵，今天才首次亮相。布泽尔表现得一个未打球的球员，未能给公牛带来太大的帮助。他们刚结束漫长的客场旅行，虽然回到主场，仍是显得疲惫。首节公牛只以2228落后，但魔术以一波164开始第二节，一举以4426拉开差距。公牛在本节打了7分钟后只投中两球，本节他们只得15分，而魔术得了33分。半场结束时，公牛以3761落后。下半场魔术一直保持两位数的优势，最多时领先了26分。森林狼86小牛100（点击观看视频集锦）小牛144七连胜。首发只有德克诺维茨基和卡隆巴特勒刚好得了10分，其他人得分都未能上双，泰森钱德勒抢下了18个篮板。替补出场的肖恩马里昂16分最高，杰森特里12分，胡安巴里亚14分。森林狼414五连败。迈克尔比斯利16分，凯文勒夫12分15个篮板，达科米利西奇12分8个篮板。小牛首发五虎状态一般，诺维茨基也此前连砍高分的，开场后命中率不高。尽管如此，小牛还是早早控制局面，在第二节还有2人22秒时以5337领先。半场结束时，森林狼只能将比分追成4355。下半场小牛继续扩大优势，第三节结束三分命中，他们以8364领先了19分。大比分领先的小牛第四节给了替补更多机会，他们很快取得20分以上的优势，早早锁定胜局。吴哥'''\n",
    "\n",
    "\n",
    "\n",
    "print(text)\n",
    "result=make_prediction(text)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "公牛遭到魔术痛击，小牛胜森林狼\n",
      "\n"
     ]
    }
   ],
   "source": [
    "text2='''\n",
    "公牛遭到魔术痛击，小牛胜森林狼\n",
    "'''\n",
    "print(text2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
